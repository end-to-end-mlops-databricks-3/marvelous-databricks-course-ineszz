<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="7" failures="0" skipped="2" tests="9" time="9.428" timestamp="2025-05-18T18:00:01.286370+03:00" hostname="LAPTOP-RU1LTQ2S"><testcase classname="tests.unit_tests.test_dataprocessor" name="test_data_ingestion" time="7.135"><error message="failed on setup with &quot;py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.&#10;: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed&#13;&#10;&#09;at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)&#13;&#10;&#09;at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)&#13;&#10;&#09;at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)&#13;&#10;&#09;at scala.Option.getOrElse(Option.scala:189)&#13;&#10;&#09;at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)&#13;&#10;&#09;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)&#13;&#10;&#09;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)&#13;&#10;&#09;at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)&#13;&#10;&#09;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)&#13;&#10;&#09;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)&#13;&#10;&#09;at py4j.Gateway.invoke(Gateway.java:238)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)&#13;&#10;&#09;at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)&#13;&#10;&#09;at py4j.ClientServerConnection.run(ClientServerConnection.java:106)&#13;&#10;&#09;at java.base/java.lang.Thread.run(Thread.java:1575)&quot;">@pytest.fixture(scope="session")
    def spark_session() -&gt; Generator[SparkSession, None, None]:
        """Create and return a SparkSession for testing.
    
        This fixture creates a SparkSession with the specified configuration and returns it for use in tests.
        """
        # One way
        # spark = SparkSession.builder.getOrCreate()  # noqa
        # Alternative way - better
        spark = (
            SparkSession.builder.master(spark_config.master)
            .appName(spark_config.app_name)
            .config("spark.executor.cores", spark_config.spark_executor_cores)
            .config("spark.executor.instances", spark_config.spark_executor_instances)
            .config("spark.sql.shuffle.partitions", spark_config.spark_sql_shuffle_partitions)
            .config("spark.driver.bindAddress", spark_config.spark_driver_bindAddress)
&gt;           .getOrCreate()
        )

tests\fixtures\datapreprocessor_fixture.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv\Lib\site-packages\pyspark\sql\session.py:497: in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
.venv\Lib\site-packages\pyspark\context.py:515: in getOrCreate
    SparkContext(conf=conf or SparkConf())
.venv\Lib\site-packages\pyspark\context.py:203: in __init__
    self._do_init(
.venv\Lib\site-packages\pyspark\context.py:296: in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
.venv\Lib\site-packages\pyspark\context.py:421: in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
.venv\Lib\site-packages\py4j\java_gateway.py:1587: in __call__
    return_value = get_return_value(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

answer = 'xro22', gateway_client = &lt;py4j.clientserver.JavaClient object at 0x0000027FF6424610&gt;, target_id = None
name = 'org.apache.spark.api.java.JavaSparkContext'

    def get_return_value(answer, gateway_client, target_id=None, name=None):
        """Converts an answer received from the Java gateway into a Python object.
    
        For example, string representation of integers are converted to Python
        integer, string representation of objects are converted to JavaObject
        instances, etc.
    
        :param answer: the string returned by the Java gateway
        :param gateway_client: the gateway client used to communicate with the Java
            Gateway. Only necessary if the answer is a reference (e.g., object,
            list, map)
        :param target_id: the name of the object from which the answer comes from
            (e.g., *object1* in `object1.hello()`). Optional.
        :param name: the name of the member from which the answer comes from
            (e.g., *hello* in `object1.hello()`). Optional.
        """
        if is_error(answer)[0]:
            if len(answer) &gt; 1:
                type = answer[1]
                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
                if answer[1] == REFERENCE_TYPE:
&gt;                   raise Py4JJavaError(
                        "An error occurred while calling {0}{1}{2}.\n".
                        format(target_id, ".", name), value)
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed
E                   	at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)
E                   	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)
E                   	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)
E                   	at scala.Option.getOrElse(Option.scala:189)
E                   	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)
E                   	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)
E                   	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:1575)

.venv\Lib\site-packages\py4j\protocol.py:326: Py4JJavaError</error></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_dataprocessor_init" time="0.001"><error message="failed on setup with &quot;py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.&#10;: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed&#13;&#10;&#09;at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)&#13;&#10;&#09;at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)&#13;&#10;&#09;at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)&#13;&#10;&#09;at scala.Option.getOrElse(Option.scala:189)&#13;&#10;&#09;at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)&#13;&#10;&#09;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)&#13;&#10;&#09;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)&#13;&#10;&#09;at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)&#13;&#10;&#09;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)&#13;&#10;&#09;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)&#13;&#10;&#09;at py4j.Gateway.invoke(Gateway.java:238)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)&#13;&#10;&#09;at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)&#13;&#10;&#09;at py4j.ClientServerConnection.run(ClientServerConnection.java:106)&#13;&#10;&#09;at java.base/java.lang.Thread.run(Thread.java:1575)&quot;">@pytest.fixture(scope="session")
    def spark_session() -&gt; Generator[SparkSession, None, None]:
        """Create and return a SparkSession for testing.
    
        This fixture creates a SparkSession with the specified configuration and returns it for use in tests.
        """
        # One way
        # spark = SparkSession.builder.getOrCreate()  # noqa
        # Alternative way - better
        spark = (
            SparkSession.builder.master(spark_config.master)
            .appName(spark_config.app_name)
            .config("spark.executor.cores", spark_config.spark_executor_cores)
            .config("spark.executor.instances", spark_config.spark_executor_instances)
            .config("spark.sql.shuffle.partitions", spark_config.spark_sql_shuffle_partitions)
            .config("spark.driver.bindAddress", spark_config.spark_driver_bindAddress)
&gt;           .getOrCreate()
        )

tests\fixtures\datapreprocessor_fixture.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv\Lib\site-packages\pyspark\sql\session.py:497: in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
.venv\Lib\site-packages\pyspark\context.py:515: in getOrCreate
    SparkContext(conf=conf or SparkConf())
.venv\Lib\site-packages\pyspark\context.py:203: in __init__
    self._do_init(
.venv\Lib\site-packages\pyspark\context.py:296: in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
.venv\Lib\site-packages\pyspark\context.py:421: in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
.venv\Lib\site-packages\py4j\java_gateway.py:1587: in __call__
    return_value = get_return_value(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

answer = 'xro22', gateway_client = &lt;py4j.clientserver.JavaClient object at 0x0000027FF6424610&gt;, target_id = None
name = 'org.apache.spark.api.java.JavaSparkContext'

    def get_return_value(answer, gateway_client, target_id=None, name=None):
        """Converts an answer received from the Java gateway into a Python object.
    
        For example, string representation of integers are converted to Python
        integer, string representation of objects are converted to JavaObject
        instances, etc.
    
        :param answer: the string returned by the Java gateway
        :param gateway_client: the gateway client used to communicate with the Java
            Gateway. Only necessary if the answer is a reference (e.g., object,
            list, map)
        :param target_id: the name of the object from which the answer comes from
            (e.g., *object1* in `object1.hello()`). Optional.
        :param name: the name of the member from which the answer comes from
            (e.g., *hello* in `object1.hello()`). Optional.
        """
        if is_error(answer)[0]:
            if len(answer) &gt; 1:
                type = answer[1]
                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
                if answer[1] == REFERENCE_TYPE:
&gt;                   raise Py4JJavaError(
                        "An error occurred while calling {0}{1}{2}.\n".
                        format(target_id, ".", name), value)
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed
E                   	at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)
E                   	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)
E                   	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)
E                   	at scala.Option.getOrElse(Option.scala:189)
E                   	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)
E                   	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)
E                   	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:1575)

.venv\Lib\site-packages\py4j\protocol.py:326: Py4JJavaError</error></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_column_transformations" time="0.001"><error message="failed on setup with &quot;py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.&#10;: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed&#13;&#10;&#09;at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)&#13;&#10;&#09;at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)&#13;&#10;&#09;at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)&#13;&#10;&#09;at scala.Option.getOrElse(Option.scala:189)&#13;&#10;&#09;at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)&#13;&#10;&#09;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)&#13;&#10;&#09;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)&#13;&#10;&#09;at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)&#13;&#10;&#09;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)&#13;&#10;&#09;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)&#13;&#10;&#09;at py4j.Gateway.invoke(Gateway.java:238)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)&#13;&#10;&#09;at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)&#13;&#10;&#09;at py4j.ClientServerConnection.run(ClientServerConnection.java:106)&#13;&#10;&#09;at java.base/java.lang.Thread.run(Thread.java:1575)&quot;">@pytest.fixture(scope="session")
    def spark_session() -&gt; Generator[SparkSession, None, None]:
        """Create and return a SparkSession for testing.
    
        This fixture creates a SparkSession with the specified configuration and returns it for use in tests.
        """
        # One way
        # spark = SparkSession.builder.getOrCreate()  # noqa
        # Alternative way - better
        spark = (
            SparkSession.builder.master(spark_config.master)
            .appName(spark_config.app_name)
            .config("spark.executor.cores", spark_config.spark_executor_cores)
            .config("spark.executor.instances", spark_config.spark_executor_instances)
            .config("spark.sql.shuffle.partitions", spark_config.spark_sql_shuffle_partitions)
            .config("spark.driver.bindAddress", spark_config.spark_driver_bindAddress)
&gt;           .getOrCreate()
        )

tests\fixtures\datapreprocessor_fixture.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv\Lib\site-packages\pyspark\sql\session.py:497: in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
.venv\Lib\site-packages\pyspark\context.py:515: in getOrCreate
    SparkContext(conf=conf or SparkConf())
.venv\Lib\site-packages\pyspark\context.py:203: in __init__
    self._do_init(
.venv\Lib\site-packages\pyspark\context.py:296: in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
.venv\Lib\site-packages\pyspark\context.py:421: in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
.venv\Lib\site-packages\py4j\java_gateway.py:1587: in __call__
    return_value = get_return_value(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

answer = 'xro22', gateway_client = &lt;py4j.clientserver.JavaClient object at 0x0000027FF6424610&gt;, target_id = None
name = 'org.apache.spark.api.java.JavaSparkContext'

    def get_return_value(answer, gateway_client, target_id=None, name=None):
        """Converts an answer received from the Java gateway into a Python object.
    
        For example, string representation of integers are converted to Python
        integer, string representation of objects are converted to JavaObject
        instances, etc.
    
        :param answer: the string returned by the Java gateway
        :param gateway_client: the gateway client used to communicate with the Java
            Gateway. Only necessary if the answer is a reference (e.g., object,
            list, map)
        :param target_id: the name of the object from which the answer comes from
            (e.g., *object1* in `object1.hello()`). Optional.
        :param name: the name of the member from which the answer comes from
            (e.g., *hello* in `object1.hello()`). Optional.
        """
        if is_error(answer)[0]:
            if len(answer) &gt; 1:
                type = answer[1]
                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
                if answer[1] == REFERENCE_TYPE:
&gt;                   raise Py4JJavaError(
                        "An error occurred while calling {0}{1}{2}.\n".
                        format(target_id, ".", name), value)
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed
E                   	at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)
E                   	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)
E                   	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)
E                   	at scala.Option.getOrElse(Option.scala:189)
E                   	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)
E                   	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)
E                   	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:1575)

.venv\Lib\site-packages\py4j\protocol.py:326: Py4JJavaError</error></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_missing_value_handling" time="0.001"><error message="failed on setup with &quot;py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.&#10;: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed&#13;&#10;&#09;at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)&#13;&#10;&#09;at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)&#13;&#10;&#09;at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)&#13;&#10;&#09;at scala.Option.getOrElse(Option.scala:189)&#13;&#10;&#09;at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)&#13;&#10;&#09;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)&#13;&#10;&#09;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)&#13;&#10;&#09;at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)&#13;&#10;&#09;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)&#13;&#10;&#09;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)&#13;&#10;&#09;at py4j.Gateway.invoke(Gateway.java:238)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)&#13;&#10;&#09;at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)&#13;&#10;&#09;at py4j.ClientServerConnection.run(ClientServerConnection.java:106)&#13;&#10;&#09;at java.base/java.lang.Thread.run(Thread.java:1575)&quot;">@pytest.fixture(scope="session")
    def spark_session() -&gt; Generator[SparkSession, None, None]:
        """Create and return a SparkSession for testing.
    
        This fixture creates a SparkSession with the specified configuration and returns it for use in tests.
        """
        # One way
        # spark = SparkSession.builder.getOrCreate()  # noqa
        # Alternative way - better
        spark = (
            SparkSession.builder.master(spark_config.master)
            .appName(spark_config.app_name)
            .config("spark.executor.cores", spark_config.spark_executor_cores)
            .config("spark.executor.instances", spark_config.spark_executor_instances)
            .config("spark.sql.shuffle.partitions", spark_config.spark_sql_shuffle_partitions)
            .config("spark.driver.bindAddress", spark_config.spark_driver_bindAddress)
&gt;           .getOrCreate()
        )

tests\fixtures\datapreprocessor_fixture.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv\Lib\site-packages\pyspark\sql\session.py:497: in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
.venv\Lib\site-packages\pyspark\context.py:515: in getOrCreate
    SparkContext(conf=conf or SparkConf())
.venv\Lib\site-packages\pyspark\context.py:203: in __init__
    self._do_init(
.venv\Lib\site-packages\pyspark\context.py:296: in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
.venv\Lib\site-packages\pyspark\context.py:421: in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
.venv\Lib\site-packages\py4j\java_gateway.py:1587: in __call__
    return_value = get_return_value(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

answer = 'xro22', gateway_client = &lt;py4j.clientserver.JavaClient object at 0x0000027FF6424610&gt;, target_id = None
name = 'org.apache.spark.api.java.JavaSparkContext'

    def get_return_value(answer, gateway_client, target_id=None, name=None):
        """Converts an answer received from the Java gateway into a Python object.
    
        For example, string representation of integers are converted to Python
        integer, string representation of objects are converted to JavaObject
        instances, etc.
    
        :param answer: the string returned by the Java gateway
        :param gateway_client: the gateway client used to communicate with the Java
            Gateway. Only necessary if the answer is a reference (e.g., object,
            list, map)
        :param target_id: the name of the object from which the answer comes from
            (e.g., *object1* in `object1.hello()`). Optional.
        :param name: the name of the member from which the answer comes from
            (e.g., *hello* in `object1.hello()`). Optional.
        """
        if is_error(answer)[0]:
            if len(answer) &gt; 1:
                type = answer[1]
                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
                if answer[1] == REFERENCE_TYPE:
&gt;                   raise Py4JJavaError(
                        "An error occurred while calling {0}{1}{2}.\n".
                        format(target_id, ".", name), value)
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed
E                   	at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)
E                   	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)
E                   	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)
E                   	at scala.Option.getOrElse(Option.scala:189)
E                   	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)
E                   	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)
E                   	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:1575)

.venv\Lib\site-packages\py4j\protocol.py:326: Py4JJavaError</error></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_column_selection" time="0.001"><error message="failed on setup with &quot;py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.&#10;: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed&#13;&#10;&#09;at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)&#13;&#10;&#09;at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)&#13;&#10;&#09;at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)&#13;&#10;&#09;at scala.Option.getOrElse(Option.scala:189)&#13;&#10;&#09;at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)&#13;&#10;&#09;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)&#13;&#10;&#09;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)&#13;&#10;&#09;at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)&#13;&#10;&#09;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)&#13;&#10;&#09;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)&#13;&#10;&#09;at py4j.Gateway.invoke(Gateway.java:238)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)&#13;&#10;&#09;at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)&#13;&#10;&#09;at py4j.ClientServerConnection.run(ClientServerConnection.java:106)&#13;&#10;&#09;at java.base/java.lang.Thread.run(Thread.java:1575)&quot;">@pytest.fixture(scope="session")
    def spark_session() -&gt; Generator[SparkSession, None, None]:
        """Create and return a SparkSession for testing.
    
        This fixture creates a SparkSession with the specified configuration and returns it for use in tests.
        """
        # One way
        # spark = SparkSession.builder.getOrCreate()  # noqa
        # Alternative way - better
        spark = (
            SparkSession.builder.master(spark_config.master)
            .appName(spark_config.app_name)
            .config("spark.executor.cores", spark_config.spark_executor_cores)
            .config("spark.executor.instances", spark_config.spark_executor_instances)
            .config("spark.sql.shuffle.partitions", spark_config.spark_sql_shuffle_partitions)
            .config("spark.driver.bindAddress", spark_config.spark_driver_bindAddress)
&gt;           .getOrCreate()
        )

tests\fixtures\datapreprocessor_fixture.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv\Lib\site-packages\pyspark\sql\session.py:497: in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
.venv\Lib\site-packages\pyspark\context.py:515: in getOrCreate
    SparkContext(conf=conf or SparkConf())
.venv\Lib\site-packages\pyspark\context.py:203: in __init__
    self._do_init(
.venv\Lib\site-packages\pyspark\context.py:296: in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
.venv\Lib\site-packages\pyspark\context.py:421: in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
.venv\Lib\site-packages\py4j\java_gateway.py:1587: in __call__
    return_value = get_return_value(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

answer = 'xro22', gateway_client = &lt;py4j.clientserver.JavaClient object at 0x0000027FF6424610&gt;, target_id = None
name = 'org.apache.spark.api.java.JavaSparkContext'

    def get_return_value(answer, gateway_client, target_id=None, name=None):
        """Converts an answer received from the Java gateway into a Python object.
    
        For example, string representation of integers are converted to Python
        integer, string representation of objects are converted to JavaObject
        instances, etc.
    
        :param answer: the string returned by the Java gateway
        :param gateway_client: the gateway client used to communicate with the Java
            Gateway. Only necessary if the answer is a reference (e.g., object,
            list, map)
        :param target_id: the name of the object from which the answer comes from
            (e.g., *object1* in `object1.hello()`). Optional.
        :param name: the name of the member from which the answer comes from
            (e.g., *hello* in `object1.hello()`). Optional.
        """
        if is_error(answer)[0]:
            if len(answer) &gt; 1:
                type = answer[1]
                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
                if answer[1] == REFERENCE_TYPE:
&gt;                   raise Py4JJavaError(
                        "An error occurred while calling {0}{1}{2}.\n".
                        format(target_id, ".", name), value)
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed
E                   	at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)
E                   	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)
E                   	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)
E                   	at scala.Option.getOrElse(Option.scala:189)
E                   	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)
E                   	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)
E                   	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:1575)

.venv\Lib\site-packages\py4j\protocol.py:326: Py4JJavaError</error></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_split_data_default_params" time="0.001"><error message="failed on setup with &quot;py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.&#10;: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed&#13;&#10;&#09;at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)&#13;&#10;&#09;at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)&#13;&#10;&#09;at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)&#13;&#10;&#09;at scala.Option.getOrElse(Option.scala:189)&#13;&#10;&#09;at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)&#13;&#10;&#09;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)&#13;&#10;&#09;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)&#13;&#10;&#09;at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)&#13;&#10;&#09;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)&#13;&#10;&#09;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)&#13;&#10;&#09;at py4j.Gateway.invoke(Gateway.java:238)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)&#13;&#10;&#09;at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)&#13;&#10;&#09;at py4j.ClientServerConnection.run(ClientServerConnection.java:106)&#13;&#10;&#09;at java.base/java.lang.Thread.run(Thread.java:1575)&quot;">@pytest.fixture(scope="session")
    def spark_session() -&gt; Generator[SparkSession, None, None]:
        """Create and return a SparkSession for testing.
    
        This fixture creates a SparkSession with the specified configuration and returns it for use in tests.
        """
        # One way
        # spark = SparkSession.builder.getOrCreate()  # noqa
        # Alternative way - better
        spark = (
            SparkSession.builder.master(spark_config.master)
            .appName(spark_config.app_name)
            .config("spark.executor.cores", spark_config.spark_executor_cores)
            .config("spark.executor.instances", spark_config.spark_executor_instances)
            .config("spark.sql.shuffle.partitions", spark_config.spark_sql_shuffle_partitions)
            .config("spark.driver.bindAddress", spark_config.spark_driver_bindAddress)
&gt;           .getOrCreate()
        )

tests\fixtures\datapreprocessor_fixture.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv\Lib\site-packages\pyspark\sql\session.py:497: in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
.venv\Lib\site-packages\pyspark\context.py:515: in getOrCreate
    SparkContext(conf=conf or SparkConf())
.venv\Lib\site-packages\pyspark\context.py:203: in __init__
    self._do_init(
.venv\Lib\site-packages\pyspark\context.py:296: in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
.venv\Lib\site-packages\pyspark\context.py:421: in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
.venv\Lib\site-packages\py4j\java_gateway.py:1587: in __call__
    return_value = get_return_value(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

answer = 'xro22', gateway_client = &lt;py4j.clientserver.JavaClient object at 0x0000027FF6424610&gt;, target_id = None
name = 'org.apache.spark.api.java.JavaSparkContext'

    def get_return_value(answer, gateway_client, target_id=None, name=None):
        """Converts an answer received from the Java gateway into a Python object.
    
        For example, string representation of integers are converted to Python
        integer, string representation of objects are converted to JavaObject
        instances, etc.
    
        :param answer: the string returned by the Java gateway
        :param gateway_client: the gateway client used to communicate with the Java
            Gateway. Only necessary if the answer is a reference (e.g., object,
            list, map)
        :param target_id: the name of the object from which the answer comes from
            (e.g., *object1* in `object1.hello()`). Optional.
        :param name: the name of the member from which the answer comes from
            (e.g., *hello* in `object1.hello()`). Optional.
        """
        if is_error(answer)[0]:
            if len(answer) &gt; 1:
                type = answer[1]
                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
                if answer[1] == REFERENCE_TYPE:
&gt;                   raise Py4JJavaError(
                        "An error occurred while calling {0}{1}{2}.\n".
                        format(target_id, ".", name), value)
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed
E                   	at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)
E                   	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)
E                   	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)
E                   	at scala.Option.getOrElse(Option.scala:189)
E                   	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)
E                   	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)
E                   	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:1575)

.venv\Lib\site-packages\py4j\protocol.py:326: Py4JJavaError</error></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_preprocess_empty_dataframe" time="0.001"><error message="failed on setup with &quot;py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.&#10;: java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed&#13;&#10;&#09;at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)&#13;&#10;&#09;at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)&#13;&#10;&#09;at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)&#13;&#10;&#09;at scala.Option.getOrElse(Option.scala:189)&#13;&#10;&#09;at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)&#13;&#10;&#09;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)&#13;&#10;&#09;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)&#13;&#10;&#09;at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)&#13;&#10;&#09;at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)&#13;&#10;&#09;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)&#13;&#10;&#09;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)&#13;&#10;&#09;at py4j.Gateway.invoke(Gateway.java:238)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)&#13;&#10;&#09;at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)&#13;&#10;&#09;at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)&#13;&#10;&#09;at py4j.ClientServerConnection.run(ClientServerConnection.java:106)&#13;&#10;&#09;at java.base/java.lang.Thread.run(Thread.java:1575)&quot;">@pytest.fixture(scope="session")
    def spark_session() -&gt; Generator[SparkSession, None, None]:
        """Create and return a SparkSession for testing.
    
        This fixture creates a SparkSession with the specified configuration and returns it for use in tests.
        """
        # One way
        # spark = SparkSession.builder.getOrCreate()  # noqa
        # Alternative way - better
        spark = (
            SparkSession.builder.master(spark_config.master)
            .appName(spark_config.app_name)
            .config("spark.executor.cores", spark_config.spark_executor_cores)
            .config("spark.executor.instances", spark_config.spark_executor_instances)
            .config("spark.sql.shuffle.partitions", spark_config.spark_sql_shuffle_partitions)
            .config("spark.driver.bindAddress", spark_config.spark_driver_bindAddress)
&gt;           .getOrCreate()
        )

tests\fixtures\datapreprocessor_fixture.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv\Lib\site-packages\pyspark\sql\session.py:497: in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
.venv\Lib\site-packages\pyspark\context.py:515: in getOrCreate
    SparkContext(conf=conf or SparkConf())
.venv\Lib\site-packages\pyspark\context.py:203: in __init__
    self._do_init(
.venv\Lib\site-packages\pyspark\context.py:296: in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
.venv\Lib\site-packages\pyspark\context.py:421: in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
.venv\Lib\site-packages\py4j\java_gateway.py:1587: in __call__
    return_value = get_return_value(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

answer = 'xro22', gateway_client = &lt;py4j.clientserver.JavaClient object at 0x0000027FF6424610&gt;, target_id = None
name = 'org.apache.spark.api.java.JavaSparkContext'

    def get_return_value(answer, gateway_client, target_id=None, name=None):
        """Converts an answer received from the Java gateway into a Python object.
    
        For example, string representation of integers are converted to Python
        integer, string representation of objects are converted to JavaObject
        instances, etc.
    
        :param answer: the string returned by the Java gateway
        :param gateway_client: the gateway client used to communicate with the Java
            Gateway. Only necessary if the answer is a reference (e.g., object,
            list, map)
        :param target_id: the name of the object from which the answer comes from
            (e.g., *object1* in `object1.hello()`). Optional.
        :param name: the name of the member from which the answer comes from
            (e.g., *hello* in `object1.hello()`). Optional.
        """
        if is_error(answer)[0]:
            if len(answer) &gt; 1:
                type = answer[1]
                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)
                if answer[1] == REFERENCE_TYPE:
&gt;                   raise Py4JJavaError(
                        "An error occurred while calling {0}{1}{2}.\n".
                        format(target_id, ".", name), value)
E                   py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
E                   : java.lang.UnsupportedOperationException: getSubject is supported only if a security manager is allowed
E                   	at java.base/javax.security.auth.Subject.getSubject(Subject.java:347)
E                   	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:577)
E                   	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2416)
E                   	at scala.Option.getOrElse(Option.scala:189)
E                   	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2416)
E                   	at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:329)
E                   	at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:58)
E                   	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
E                   	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:501)
E                   	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:485)
E                   	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
E                   	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
E                   	at py4j.Gateway.invoke(Gateway.java:238)
E                   	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
E                   	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
E                   	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
E                   	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
E                   	at java.base/java.lang.Thread.run(Thread.java:1575)

.venv\Lib\site-packages\py4j\protocol.py:326: Py4JJavaError</error></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_save_to_catalog_succesfull" time="0.001"><skipped type="pytest.skip" message="depends on delta tables on Databricks">C:\Users\Ines\VSProjects\databricks_course\marvelous-databricks-course-ineszz\tests\unit_tests\test_dataprocessor.py:159: depends on delta tables on Databricks</skipped></testcase><testcase classname="tests.unit_tests.test_dataprocessor" name="test_delta_table_property_of_enableChangeDataFeed_check" time="0.000"><skipped type="pytest.skip" message="depends on delta tables on Databricks">C:\Users\Ines\VSProjects\databricks_course\marvelous-databricks-course-ineszz\tests\unit_tests\test_dataprocessor.py:183: depends on delta tables on Databricks</skipped></testcase></testsuite></testsuites>